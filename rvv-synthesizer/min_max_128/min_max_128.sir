def _Z6Min128Iu16__rvv_uint64m1_tET_S0_S0_(v0: vec<e1m1>, v1: vec<e1m1>) -> vec<e1m1>:
  (v2) = vsetvlmax[mmul=1, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vslide1down.vx[e1m1, ud, fm](v2, v0, v5)
  (v7) = vslide1down.vx[e1m1, ud, fm](v2, v1, v5)
  (v9) = vminu.vv[e1m1, ud, fm](v2, v0, v1)
  (v11) = vmsltu.vv[e1m1, ud, fm](v2, v3, v7)
  (v13) = vmseq.vv[e1m1, ud, fm](v2, v3, v7)
  (v15) = vmerge.vvm[e1m1, ud](v2, v1, v0, v11)
  (v17) = vmerge.vvm[e1m1, ud](v2, v15, v9, v13)
  (v19) = vid.v[e1m1, ud, fm](v2)
  (v22) = scalar[xmul=1, imm=0x0000000000000001]()
  (v21) = vand.vx[e1m1, ud, fm](v2, v19, v22)
  (v24) = vmseq.vx[e1m1, ud, fm](v2, v21, v5)
  (v26) = vmerge.vvm[e1m1, ud](v2, v9, v17, v24)
  return (v26)

def _Z6Max128Iu16__rvv_uint64m1_tET_S0_S0_(v0: vec<e1m1>, v1: vec<e1m1>) -> vec<e1m1>:
  (v2) = vsetvlmax[mmul=1, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vslide1down.vx[e1m1, ud, fm](v2, v0, v5)
  (v7) = vslide1down.vx[e1m1, ud, fm](v2, v1, v5)
  (v9) = vmaxu.vv[e1m1, ud, fm](v2, v0, v1)
  (v11) = vmsltu.vv[e1m1, ud, fm](v2, v3, v7)
  (v13) = vmseq.vv[e1m1, ud, fm](v2, v3, v7)
  (v15) = vmerge.vvm[e1m1, ud](v2, v0, v1, v11)
  (v17) = vmerge.vvm[e1m1, ud](v2, v15, v9, v13)
  (v19) = vid.v[e1m1, ud, fm](v2)
  (v22) = scalar[xmul=1, imm=0x0000000000000001]()
  (v21) = vand.vx[e1m1, ud, fm](v2, v19, v22)
  (v24) = vmseq.vx[e1m1, ud, fm](v2, v21, v5)
  (v26) = vmerge.vvm[e1m1, ud](v2, v9, v17, v24)
  return (v26)

def _Z11Min128UpperIu16__rvv_uint64m1_tET_S0_S0_(v0: vec<e1m1>, v1: vec<e1m1>) -> vec<e1m1>:
  (v2) = vsetvlmax[mmul=1, tama]()
  (v3) = vmsltu.vv[e1m1, ud, fm](v2, v0, v1)
  (v8) = scalar[xmul=1, imm=0x0000000000000000]()
  (v5) = scalar_to_vec[e1m1, ud](v2, v8)
  (v10) = scalar[xmul=1, imm=0xffffffffffffffff]()
  (v9) = vmerge.vxm[e1m1, ud](v2, v5, v10, v3)
  (v12) = vslide1down.vx[e1m1, ud, fm](v2, v9, v8)
  (v14) = first_element_to_scalar[e1m1](v12)
  (v16) = vid.v[e1m1, ud, fm](v2)
  (v19) = scalar[xmul=1, imm=0x0000000000000001]()
  (v18) = vand.vx[e1m1, ud, fm](v2, v16, v19)
  (v21) = vmseq.vx[e1m1, ud, fm](v2, v18, v8)
  (v23) = vmerge.vvm[e1m1, ud](v2, v9, v12, v21)
  (v25) = vmsne.vx[e1m1, ud, fm](v2, v23, v8)
  (v27) = vmerge.vvm[e1m1, ud](v2, v1, v0, v25)
  return (v27)

def _Z11Max128UpperIu16__rvv_uint64m1_tET_S0_S0_(v0: vec<e1m1>, v1: vec<e1m1>) -> vec<e1m1>:
  (v2) = vsetvlmax[mmul=1, tama]()
  (v3) = vmsltu.vv[e1m1, ud, fm](v2, v1, v0)
  (v8) = scalar[xmul=1, imm=0x0000000000000000]()
  (v5) = scalar_to_vec[e1m1, ud](v2, v8)
  (v10) = scalar[xmul=1, imm=0xffffffffffffffff]()
  (v9) = vmerge.vxm[e1m1, ud](v2, v5, v10, v3)
  (v12) = vslide1down.vx[e1m1, ud, fm](v2, v9, v8)
  (v14) = first_element_to_scalar[e1m1](v12)
  (v16) = vid.v[e1m1, ud, fm](v2)
  (v19) = scalar[xmul=1, imm=0x0000000000000001]()
  (v18) = vand.vx[e1m1, ud, fm](v2, v16, v19)
  (v21) = vmseq.vx[e1m1, ud, fm](v2, v18, v8)
  (v23) = vmerge.vvm[e1m1, ud](v2, v9, v12, v21)
  (v25) = vmsne.vx[e1m1, ud, fm](v2, v23, v8)
  (v27) = vmerge.vvm[e1m1, ud](v2, v1, v0, v25)
  return (v27)

def _Z6Min128Iu16__rvv_uint64m2_tET_S0_S0_(v0: vec<e1m2>, v1: vec<e1m2>) -> vec<e1m2>:
  (v2) = vsetvlmax[mmul=2, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vslide1down.vx[e1m2, ud, fm](v2, v0, v5)
  (v7) = vslide1down.vx[e1m2, ud, fm](v2, v1, v5)
  (v9) = vminu.vv[e1m2, ud, fm](v2, v0, v1)
  (v11) = vmsltu.vv[e1m2, ud, fm](v2, v3, v7)
  (v13) = vmseq.vv[e1m2, ud, fm](v2, v3, v7)
  (v15) = vmerge.vvm[e1m2, ud](v2, v1, v0, v11)
  (v17) = vmerge.vvm[e1m2, ud](v2, v15, v9, v13)
  (v19) = vid.v[e1m2, ud, fm](v2)
  (v22) = scalar[xmul=1, imm=0x0000000000000001]()
  (v21) = vand.vx[e1m2, ud, fm](v2, v19, v22)
  (v24) = vmseq.vx[e1m2, ud, fm](v2, v21, v5)
  (v26) = vmerge.vvm[e1m2, ud](v2, v9, v17, v24)
  return (v26)

def _Z6Max128Iu16__rvv_uint64m2_tET_S0_S0_(v0: vec<e1m2>, v1: vec<e1m2>) -> vec<e1m2>:
  (v2) = vsetvlmax[mmul=2, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vslide1down.vx[e1m2, ud, fm](v2, v0, v5)
  (v7) = vslide1down.vx[e1m2, ud, fm](v2, v1, v5)
  (v9) = vmaxu.vv[e1m2, ud, fm](v2, v0, v1)
  (v11) = vmsltu.vv[e1m2, ud, fm](v2, v3, v7)
  (v13) = vmseq.vv[e1m2, ud, fm](v2, v3, v7)
  (v15) = vmerge.vvm[e1m2, ud](v2, v0, v1, v11)
  (v17) = vmerge.vvm[e1m2, ud](v2, v15, v9, v13)
  (v19) = vid.v[e1m2, ud, fm](v2)
  (v22) = scalar[xmul=1, imm=0x0000000000000001]()
  (v21) = vand.vx[e1m2, ud, fm](v2, v19, v22)
  (v24) = vmseq.vx[e1m2, ud, fm](v2, v21, v5)
  (v26) = vmerge.vvm[e1m2, ud](v2, v9, v17, v24)
  return (v26)

def _Z11Min128UpperIu16__rvv_uint64m2_tET_S0_S0_(v0: vec<e1m2>, v1: vec<e1m2>) -> vec<e1m2>:
  (v2) = vsetvlmax[mmul=2, tama]()
  (v3) = vmsltu.vv[e1m2, ud, fm](v2, v0, v1)
  (v8) = scalar[xmul=1, imm=0x0000000000000000]()
  (v5) = scalar_to_vec[e1m2, ud](v2, v8)
  (v10) = scalar[xmul=1, imm=0xffffffffffffffff]()
  (v9) = vmerge.vxm[e1m2, ud](v2, v5, v10, v3)
  (v12) = vslide1down.vx[e1m2, ud, fm](v2, v9, v8)
  (v14) = first_element_to_scalar[e1m2](v12)
  (v16) = vid.v[e1m2, ud, fm](v2)
  (v19) = scalar[xmul=1, imm=0x0000000000000001]()
  (v18) = vand.vx[e1m2, ud, fm](v2, v16, v19)
  (v21) = vmseq.vx[e1m2, ud, fm](v2, v18, v8)
  (v23) = vmerge.vvm[e1m2, ud](v2, v9, v12, v21)
  (v25) = vmsne.vx[e1m2, ud, fm](v2, v23, v8)
  (v27) = vmerge.vvm[e1m2, ud](v2, v1, v0, v25)
  return (v27)

def _Z11Max128UpperIu16__rvv_uint64m2_tET_S0_S0_(v0: vec<e1m2>, v1: vec<e1m2>) -> vec<e1m2>:
  (v2) = vsetvlmax[mmul=2, tama]()
  (v3) = vmsltu.vv[e1m2, ud, fm](v2, v1, v0)
  (v8) = scalar[xmul=1, imm=0x0000000000000000]()
  (v5) = scalar_to_vec[e1m2, ud](v2, v8)
  (v10) = scalar[xmul=1, imm=0xffffffffffffffff]()
  (v9) = vmerge.vxm[e1m2, ud](v2, v5, v10, v3)
  (v12) = vslide1down.vx[e1m2, ud, fm](v2, v9, v8)
  (v14) = first_element_to_scalar[e1m2](v12)
  (v16) = vid.v[e1m2, ud, fm](v2)
  (v19) = scalar[xmul=1, imm=0x0000000000000001]()
  (v18) = vand.vx[e1m2, ud, fm](v2, v16, v19)
  (v21) = vmseq.vx[e1m2, ud, fm](v2, v18, v8)
  (v23) = vmerge.vvm[e1m2, ud](v2, v9, v12, v21)
  (v25) = vmsne.vx[e1m2, ud, fm](v2, v23, v8)
  (v27) = vmerge.vvm[e1m2, ud](v2, v1, v0, v25)
  return (v27)

def _Z6Min128Iu16__rvv_uint64m4_tET_S0_S0_(v0: vec<e1m4>, v1: vec<e1m4>) -> vec<e1m4>:
  (v2) = vsetvlmax[mmul=4, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vslide1down.vx[e1m4, ud, fm](v2, v0, v5)
  (v7) = vslide1down.vx[e1m4, ud, fm](v2, v1, v5)
  (v9) = vminu.vv[e1m4, ud, fm](v2, v0, v1)
  (v11) = vmsltu.vv[e1m4, ud, fm](v2, v3, v7)
  (v13) = vmseq.vv[e1m4, ud, fm](v2, v3, v7)
  (v15) = vmerge.vvm[e1m4, ud](v2, v1, v0, v11)
  (v17) = vmerge.vvm[e1m4, ud](v2, v15, v9, v13)
  (v19) = vid.v[e1m4, ud, fm](v2)
  (v22) = scalar[xmul=1, imm=0x0000000000000001]()
  (v21) = vand.vx[e1m4, ud, fm](v2, v19, v22)
  (v24) = vmseq.vx[e1m4, ud, fm](v2, v21, v5)
  (v26) = vmerge.vvm[e1m4, ud](v2, v9, v17, v24)
  return (v26)

def _Z6Max128Iu16__rvv_uint64m4_tET_S0_S0_(v0: vec<e1m4>, v1: vec<e1m4>) -> vec<e1m4>:
  (v2) = vsetvlmax[mmul=4, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vslide1down.vx[e1m4, ud, fm](v2, v0, v5)
  (v7) = vslide1down.vx[e1m4, ud, fm](v2, v1, v5)
  (v9) = vmaxu.vv[e1m4, ud, fm](v2, v0, v1)
  (v11) = vmsltu.vv[e1m4, ud, fm](v2, v3, v7)
  (v13) = vmseq.vv[e1m4, ud, fm](v2, v3, v7)
  (v15) = vmerge.vvm[e1m4, ud](v2, v0, v1, v11)
  (v17) = vmerge.vvm[e1m4, ud](v2, v15, v9, v13)
  (v19) = vid.v[e1m4, ud, fm](v2)
  (v22) = scalar[xmul=1, imm=0x0000000000000001]()
  (v21) = vand.vx[e1m4, ud, fm](v2, v19, v22)
  (v24) = vmseq.vx[e1m4, ud, fm](v2, v21, v5)
  (v26) = vmerge.vvm[e1m4, ud](v2, v9, v17, v24)
  return (v26)

def _Z11Min128UpperIu16__rvv_uint64m4_tET_S0_S0_(v0: vec<e1m4>, v1: vec<e1m4>) -> vec<e1m4>:
  (v2) = vsetvlmax[mmul=4, tama]()
  (v3) = vmsltu.vv[e1m4, ud, fm](v2, v0, v1)
  (v8) = scalar[xmul=1, imm=0x0000000000000000]()
  (v5) = scalar_to_vec[e1m4, ud](v2, v8)
  (v10) = scalar[xmul=1, imm=0xffffffffffffffff]()
  (v9) = vmerge.vxm[e1m4, ud](v2, v5, v10, v3)
  (v12) = vslide1down.vx[e1m4, ud, fm](v2, v9, v8)
  (v14) = first_element_to_scalar[e1m4](v12)
  (v16) = vid.v[e1m4, ud, fm](v2)
  (v19) = scalar[xmul=1, imm=0x0000000000000001]()
  (v18) = vand.vx[e1m4, ud, fm](v2, v16, v19)
  (v21) = vmseq.vx[e1m4, ud, fm](v2, v18, v8)
  (v23) = vmerge.vvm[e1m4, ud](v2, v9, v12, v21)
  (v25) = vmsne.vx[e1m4, ud, fm](v2, v23, v8)
  (v27) = vmerge.vvm[e1m4, ud](v2, v1, v0, v25)
  return (v27)

def _Z11Max128UpperIu16__rvv_uint64m4_tET_S0_S0_(v0: vec<e1m4>, v1: vec<e1m4>) -> vec<e1m4>:
  (v2) = vsetvlmax[mmul=4, tama]()
  (v3) = vmsltu.vv[e1m4, ud, fm](v2, v1, v0)
  (v8) = scalar[xmul=1, imm=0x0000000000000000]()
  (v5) = scalar_to_vec[e1m4, ud](v2, v8)
  (v10) = scalar[xmul=1, imm=0xffffffffffffffff]()
  (v9) = vmerge.vxm[e1m4, ud](v2, v5, v10, v3)
  (v12) = vslide1down.vx[e1m4, ud, fm](v2, v9, v8)
  (v14) = first_element_to_scalar[e1m4](v12)
  (v16) = vid.v[e1m4, ud, fm](v2)
  (v19) = scalar[xmul=1, imm=0x0000000000000001]()
  (v18) = vand.vx[e1m4, ud, fm](v2, v16, v19)
  (v21) = vmseq.vx[e1m4, ud, fm](v2, v18, v8)
  (v23) = vmerge.vvm[e1m4, ud](v2, v9, v12, v21)
  (v25) = vmsne.vx[e1m4, ud, fm](v2, v23, v8)
  (v27) = vmerge.vvm[e1m4, ud](v2, v1, v0, v25)
  return (v27)

def _Z6Min128Iu16__rvv_uint64m8_tET_S0_S0_(v0: vec<e1m8>, v1: vec<e1m8>) -> vec<e1m8>:
  (v2) = vsetvlmax[mmul=8, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vslide1down.vx[e1m8, ud, fm](v2, v0, v5)
  (v7) = vslide1down.vx[e1m8, ud, fm](v2, v1, v5)
  (v9) = vminu.vv[e1m8, ud, fm](v2, v0, v1)
  (v11) = vmsltu.vv[e1m8, ud, fm](v2, v3, v7)
  (v13) = vmseq.vv[e1m8, ud, fm](v2, v3, v7)
  (v15) = vmerge.vvm[e1m8, ud](v2, v1, v0, v11)
  (v17) = vmerge.vvm[e1m8, ud](v2, v15, v9, v13)
  (v19) = vid.v[e1m8, ud, fm](v2)
  (v22) = scalar[xmul=1, imm=0x0000000000000001]()
  (v21) = vand.vx[e1m8, ud, fm](v2, v19, v22)
  (v24) = vmseq.vx[e1m8, ud, fm](v2, v21, v5)
  (v26) = vmerge.vvm[e1m8, ud](v2, v9, v17, v24)
  return (v26)

def _Z6Max128Iu16__rvv_uint64m8_tET_S0_S0_(v0: vec<e1m8>, v1: vec<e1m8>) -> vec<e1m8>:
  (v2) = vsetvlmax[mmul=8, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vslide1down.vx[e1m8, ud, fm](v2, v0, v5)
  (v7) = vslide1down.vx[e1m8, ud, fm](v2, v1, v5)
  (v9) = vmaxu.vv[e1m8, ud, fm](v2, v0, v1)
  (v11) = vmsltu.vv[e1m8, ud, fm](v2, v3, v7)
  (v13) = vmseq.vv[e1m8, ud, fm](v2, v3, v7)
  (v15) = vmerge.vvm[e1m8, ud](v2, v0, v1, v11)
  (v17) = vmerge.vvm[e1m8, ud](v2, v15, v9, v13)
  (v19) = vid.v[e1m8, ud, fm](v2)
  (v22) = scalar[xmul=1, imm=0x0000000000000001]()
  (v21) = vand.vx[e1m8, ud, fm](v2, v19, v22)
  (v24) = vmseq.vx[e1m8, ud, fm](v2, v21, v5)
  (v26) = vmerge.vvm[e1m8, ud](v2, v9, v17, v24)
  return (v26)

def _Z11Min128UpperIu16__rvv_uint64m8_tET_S0_S0_(v0: vec<e1m8>, v1: vec<e1m8>) -> vec<e1m8>:
  (v2) = vsetvlmax[mmul=8, tama]()
  (v3) = vmsltu.vv[e1m8, ud, fm](v2, v0, v1)
  (v8) = scalar[xmul=1, imm=0x0000000000000000]()
  (v5) = scalar_to_vec[e1m8, ud](v2, v8)
  (v10) = scalar[xmul=1, imm=0xffffffffffffffff]()
  (v9) = vmerge.vxm[e1m8, ud](v2, v5, v10, v3)
  (v12) = vslide1down.vx[e1m8, ud, fm](v2, v9, v8)
  (v14) = first_element_to_scalar[e1m8](v12)
  (v16) = vid.v[e1m8, ud, fm](v2)
  (v19) = scalar[xmul=1, imm=0x0000000000000001]()
  (v18) = vand.vx[e1m8, ud, fm](v2, v16, v19)
  (v21) = vmseq.vx[e1m8, ud, fm](v2, v18, v8)
  (v23) = vmerge.vvm[e1m8, ud](v2, v9, v12, v21)
  (v25) = vmsne.vx[e1m8, ud, fm](v2, v23, v8)
  (v27) = vmerge.vvm[e1m8, ud](v2, v1, v0, v25)
  return (v27)

def _Z11Max128UpperIu16__rvv_uint64m8_tET_S0_S0_(v0: vec<e1m8>, v1: vec<e1m8>) -> vec<e1m8>:
  (v2) = vsetvlmax[mmul=8, tama]()
  (v3) = vmsltu.vv[e1m8, ud, fm](v2, v1, v0)
  (v8) = scalar[xmul=1, imm=0x0000000000000000]()
  (v5) = scalar_to_vec[e1m8, ud](v2, v8)
  (v10) = scalar[xmul=1, imm=0xffffffffffffffff]()
  (v9) = vmerge.vxm[e1m8, ud](v2, v5, v10, v3)
  (v12) = vslide1down.vx[e1m8, ud, fm](v2, v9, v8)
  (v14) = first_element_to_scalar[e1m8](v12)
  (v16) = vid.v[e1m8, ud, fm](v2)
  (v19) = scalar[xmul=1, imm=0x0000000000000001]()
  (v18) = vand.vx[e1m8, ud, fm](v2, v16, v19)
  (v21) = vmseq.vx[e1m8, ud, fm](v2, v18, v8)
  (v23) = vmerge.vvm[e1m8, ud](v2, v9, v12, v21)
  (v25) = vmsne.vx[e1m8, ud, fm](v2, v23, v8)
  (v27) = vmerge.vvm[e1m8, ud](v2, v1, v0, v25)
  return (v27)

