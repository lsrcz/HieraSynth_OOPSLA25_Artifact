def _Z6AddSubIu16__rvv_uint8mf8_tET_S0_S0_(v0: vec<ef8mf8>, v1: vec<ef8mf8>) -> vec<ef8mf8>:
  (v2) = vsetvlmax[mmul=1, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8mf8, ud, fm](v2, v1, v5)
  (v7) = vlenb()
  (v8) = scalar[xmul=1, imm=0x0000000000000004]()
  (v9) = srl.xx[width=1](v7, v8)
  (v10) = scalar[xmul=1, imm=0x0000000000000200]()
  (v11) = minu.xx[width=1](v9, v10)
  (v14) = vsetvl[mmul=1, tama](v11)
  (v15) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v12) = scalar_to_vec[ef4mf4, ud](v14, v15)
  (v16) = vec_to_vec[src=ef4mf4, dest=ef8mf4](v12)
  (v17) = vget[part=ef8mf8, src=ef8mf4, idx=0](v16)
  (v19) = vsetvlrelay[mmul=1, src_mmul=1, tama](v2)
  (v18) = vmsne.vx[ef8mf8, ud, fm](v19, v17, v5)
  (v20) = vmerge.vvm[ef8mf8, ud](v19, v1, v3, v18)
  (v22) = vadd.vv[ef8mf8, ud, fm](v19, v0, v20)
  return (v22)

def _Z6AddSubIu16__rvv_uint8mf4_tET_S0_S0_(v0: vec<ef8mf4>, v1: vec<ef8mf4>) -> vec<ef8mf4>:
  (v2) = vsetvlmax[mmul=2, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8mf4, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=1, tama]()
  (v11) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef4mf4, ud](v7, v11)
  (v12) = vec_to_vec[src=ef4mf4, dest=ef8mf4](v8)
  (v14) = vsetvlrelay[mmul=2, src_mmul=2, tama](v2)
  (v13) = vmsne.vx[ef8mf4, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef8mf4, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef8mf4, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu16__rvv_uint8mf2_tET_S0_S0_(v0: vec<ef8mf2>, v1: vec<ef8mf2>) -> vec<ef8mf2>:
  (v2) = vsetvlmax[mmul=4, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8mf2, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=2, tama]()
  (v11) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef4mf2, ud](v7, v11)
  (v12) = vec_to_vec[src=ef4mf2, dest=ef8mf2](v8)
  (v14) = vsetvlrelay[mmul=4, src_mmul=4, tama](v2)
  (v13) = vmsne.vx[ef8mf2, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef8mf2, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef8mf2, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu15__rvv_uint8m1_tET_S0_S0_(v0: vec<ef8m1>, v1: vec<ef8m1>) -> vec<ef8m1>:
  (v2) = vsetvlmax[mmul=8, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8m1, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=4, tama]()
  (v11) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef4m1, ud](v7, v11)
  (v12) = vec_to_vec[src=ef4m1, dest=ef8m1](v8)
  (v14) = vsetvlrelay[mmul=8, src_mmul=8, tama](v2)
  (v13) = vmsne.vx[ef8m1, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef8m1, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef8m1, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu15__rvv_uint8m2_tET_S0_S0_(v0: vec<ef8m2>, v1: vec<ef8m2>) -> vec<ef8m2>:
  (v2) = vsetvlmax[mmul=16, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8m2, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=8, tama]()
  (v11) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef4m2, ud](v7, v11)
  (v12) = vec_to_vec[src=ef4m2, dest=ef8m2](v8)
  (v14) = vsetvlrelay[mmul=16, src_mmul=16, tama](v2)
  (v13) = vmsne.vx[ef8m2, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef8m2, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef8m2, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu15__rvv_uint8m4_tET_S0_S0_(v0: vec<ef8m4>, v1: vec<ef8m4>) -> vec<ef8m4>:
  (v2) = vsetvlmax[mmul=32, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8m4, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=16, tama]()
  (v11) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef4m4, ud](v7, v11)
  (v12) = vec_to_vec[src=ef4m4, dest=ef8m4](v8)
  (v14) = vsetvlrelay[mmul=32, src_mmul=32, tama](v2)
  (v13) = vmsne.vx[ef8m4, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef8m4, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef8m4, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu15__rvv_uint8m8_tET_S0_S0_(v0: vec<ef8m8>, v1: vec<ef8m8>) -> vec<ef8m8>:
  (v2) = vsetvlmax[mmul=64, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8m8, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=32, tama]()
  (v11) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef4m8, ud](v7, v11)
  (v12) = vec_to_vec[src=ef4m8, dest=ef8m8](v8)
  (v14) = vsetvlrelay[mmul=64, src_mmul=64, tama](v2)
  (v13) = vmsne.vx[ef8m8, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef8m8, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef8m8, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu17__rvv_uint16mf4_tET_S0_S0_(v0: vec<ef4mf4>, v1: vec<ef4mf4>) -> vec<ef4mf4>:
  (v2) = vsetvlmax[mmul=1, tama]()
  (v5) = scalar[xmul=f4, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef4mf4, ud, fm](v2, v1, v5)
  (v7) = vlenb()
  (v8) = scalar[xmul=1, imm=0x0000000000000004]()
  (v9) = srl.xx[width=1](v7, v8)
  (v10) = scalar[xmul=1, imm=0x0000000000000200]()
  (v11) = minu.xx[width=1](v9, v10)
  (v14) = vsetvl[mmul=1, tama](v11)
  (v15) = scalar[xmul=f2, imm=0x0000000000000001]()
  (v12) = scalar_to_vec[ef2mf2, ud](v14, v15)
  (v16) = vec_to_vec[src=ef2mf2, dest=ef8mf2](v12)
  (v17) = vget[part=ef8mf4, src=ef8mf2, idx=0](v16)
  (v18) = vec_to_vec[src=ef8mf4, dest=ef4mf4](v17)
  (v20) = vsetvlrelay[mmul=1, src_mmul=1, tama](v2)
  (v19) = vmsne.vx[ef4mf4, ud, fm](v20, v18, v5)
  (v21) = vmerge.vvm[ef4mf4, ud](v20, v1, v3, v19)
  (v23) = vadd.vv[ef4mf4, ud, fm](v20, v0, v21)
  return (v23)

def _Z6AddSubIu17__rvv_uint16mf2_tET_S0_S0_(v0: vec<ef4mf2>, v1: vec<ef4mf2>) -> vec<ef4mf2>:
  (v2) = vsetvlmax[mmul=2, tama]()
  (v5) = scalar[xmul=f4, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef4mf2, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=1, tama]()
  (v11) = scalar[xmul=f2, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef2mf2, ud](v7, v11)
  (v12) = vec_to_vec[src=ef2mf2, dest=ef4mf2](v8)
  (v14) = vsetvlrelay[mmul=2, src_mmul=2, tama](v2)
  (v13) = vmsne.vx[ef4mf2, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef4mf2, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef4mf2, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu16__rvv_uint16m1_tET_S0_S0_(v0: vec<ef4m1>, v1: vec<ef4m1>) -> vec<ef4m1>:
  (v2) = vsetvlmax[mmul=4, tama]()
  (v5) = scalar[xmul=f4, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef4m1, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=2, tama]()
  (v11) = scalar[xmul=f2, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef2m1, ud](v7, v11)
  (v12) = vec_to_vec[src=ef2m1, dest=ef4m1](v8)
  (v14) = vsetvlrelay[mmul=4, src_mmul=4, tama](v2)
  (v13) = vmsne.vx[ef4m1, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef4m1, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef4m1, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu16__rvv_uint16m2_tET_S0_S0_(v0: vec<ef4m2>, v1: vec<ef4m2>) -> vec<ef4m2>:
  (v2) = vsetvlmax[mmul=8, tama]()
  (v5) = scalar[xmul=f4, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef4m2, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=4, tama]()
  (v11) = scalar[xmul=f2, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef2m2, ud](v7, v11)
  (v12) = vec_to_vec[src=ef2m2, dest=ef4m2](v8)
  (v14) = vsetvlrelay[mmul=8, src_mmul=8, tama](v2)
  (v13) = vmsne.vx[ef4m2, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef4m2, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef4m2, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu16__rvv_uint16m4_tET_S0_S0_(v0: vec<ef4m4>, v1: vec<ef4m4>) -> vec<ef4m4>:
  (v2) = vsetvlmax[mmul=16, tama]()
  (v5) = scalar[xmul=f4, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef4m4, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=8, tama]()
  (v11) = scalar[xmul=f2, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef2m4, ud](v7, v11)
  (v12) = vec_to_vec[src=ef2m4, dest=ef4m4](v8)
  (v14) = vsetvlrelay[mmul=16, src_mmul=16, tama](v2)
  (v13) = vmsne.vx[ef4m4, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef4m4, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef4m4, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu16__rvv_uint16m8_tET_S0_S0_(v0: vec<ef4m8>, v1: vec<ef4m8>) -> vec<ef4m8>:
  (v2) = vsetvlmax[mmul=32, tama]()
  (v5) = scalar[xmul=f4, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef4m8, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=16, tama]()
  (v11) = scalar[xmul=f2, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef2m8, ud](v7, v11)
  (v12) = vec_to_vec[src=ef2m8, dest=ef4m8](v8)
  (v14) = vsetvlrelay[mmul=32, src_mmul=32, tama](v2)
  (v13) = vmsne.vx[ef4m8, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef4m8, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef4m8, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu17__rvv_uint32mf2_tET_S0_S0_(v0: vec<ef2mf2>, v1: vec<ef2mf2>) -> vec<ef2mf2>:
  (v2) = vsetvlmax[mmul=1, tama]()
  (v5) = scalar[xmul=f2, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef2mf2, ud, fm](v2, v1, v5)
  (v7) = vlenb()
  (v8) = scalar[xmul=1, imm=0x0000000000000004]()
  (v9) = srl.xx[width=1](v7, v8)
  (v10) = scalar[xmul=1, imm=0x0000000000000200]()
  (v11) = minu.xx[width=1](v9, v10)
  (v14) = vsetvl[mmul=1, tama](v11)
  (v15) = scalar[xmul=1, imm=0x0000000000000001]()
  (v12) = scalar_to_vec[e1m1, ud](v14, v15)
  (v16) = vec_to_vec[src=e1m1, dest=ef8m1](v12)
  (v17) = vget[part=ef8mf2, src=ef8m1, idx=0](v16)
  (v18) = vec_to_vec[src=ef8mf2, dest=ef2mf2](v17)
  (v20) = vsetvlrelay[mmul=1, src_mmul=1, tama](v2)
  (v19) = vmsne.vx[ef2mf2, ud, fm](v20, v18, v5)
  (v21) = vmerge.vvm[ef2mf2, ud](v20, v1, v3, v19)
  (v23) = vadd.vv[ef2mf2, ud, fm](v20, v0, v21)
  return (v23)

def _Z6AddSubIu16__rvv_uint32m1_tET_S0_S0_(v0: vec<ef2m1>, v1: vec<ef2m1>) -> vec<ef2m1>:
  (v2) = vsetvlmax[mmul=2, tama]()
  (v5) = scalar[xmul=f2, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef2m1, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=1, tama]()
  (v11) = scalar[xmul=1, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[e1m1, ud](v7, v11)
  (v12) = vec_to_vec[src=e1m1, dest=ef2m1](v8)
  (v14) = vsetvlrelay[mmul=2, src_mmul=2, tama](v2)
  (v13) = vmsne.vx[ef2m1, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef2m1, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef2m1, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu16__rvv_uint32m2_tET_S0_S0_(v0: vec<ef2m2>, v1: vec<ef2m2>) -> vec<ef2m2>:
  (v2) = vsetvlmax[mmul=4, tama]()
  (v5) = scalar[xmul=f2, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef2m2, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=2, tama]()
  (v11) = scalar[xmul=1, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[e1m2, ud](v7, v11)
  (v12) = vec_to_vec[src=e1m2, dest=ef2m2](v8)
  (v14) = vsetvlrelay[mmul=4, src_mmul=4, tama](v2)
  (v13) = vmsne.vx[ef2m2, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef2m2, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef2m2, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu16__rvv_uint32m4_tET_S0_S0_(v0: vec<ef2m4>, v1: vec<ef2m4>) -> vec<ef2m4>:
  (v2) = vsetvlmax[mmul=8, tama]()
  (v5) = scalar[xmul=f2, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef2m4, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=4, tama]()
  (v11) = scalar[xmul=1, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[e1m4, ud](v7, v11)
  (v12) = vec_to_vec[src=e1m4, dest=ef2m4](v8)
  (v14) = vsetvlrelay[mmul=8, src_mmul=8, tama](v2)
  (v13) = vmsne.vx[ef2m4, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef2m4, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef2m4, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu16__rvv_uint32m8_tET_S0_S0_(v0: vec<ef2m8>, v1: vec<ef2m8>) -> vec<ef2m8>:
  (v2) = vsetvlmax[mmul=16, tama]()
  (v5) = scalar[xmul=f2, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef2m8, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=8, tama]()
  (v11) = scalar[xmul=1, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[e1m8, ud](v7, v11)
  (v12) = vec_to_vec[src=e1m8, dest=ef2m8](v8)
  (v14) = vsetvlrelay[mmul=16, src_mmul=16, tama](v2)
  (v13) = vmsne.vx[ef2m8, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef2m8, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef2m8, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu16__rvv_uint64m1_tET_S0_S0_(v0: vec<e1m1>, v1: vec<e1m1>) -> vec<e1m1>:
  (v2) = vsetvlmax[mmul=1, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vrsub.vx[e1m1, ud, fm](v2, v1, v5)
  (v7) = vid.v[e1m1, ud, fm](v2)
  (v10) = scalar[xmul=1, imm=0x0000000000000001]()
  (v9) = vand.vx[e1m1, ud, fm](v2, v7, v10)
  (v12) = vmseq.vx[e1m1, ud, fm](v2, v9, v5)
  (v14) = vmerge.vvm[e1m1, ud](v2, v1, v3, v12)
  (v16) = vadd.vv[e1m1, ud, fm](v2, v0, v14)
  return (v16)

def _Z6AddSubIu16__rvv_uint64m2_tET_S0_S0_(v0: vec<e1m2>, v1: vec<e1m2>) -> vec<e1m2>:
  (v2) = vsetvlmax[mmul=2, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vrsub.vx[e1m2, ud, fm](v2, v1, v5)
  (v7) = vid.v[e1m2, ud, fm](v2)
  (v10) = scalar[xmul=1, imm=0x0000000000000001]()
  (v9) = vand.vx[e1m2, ud, fm](v2, v7, v10)
  (v12) = vmseq.vx[e1m2, ud, fm](v2, v9, v5)
  (v14) = vmerge.vvm[e1m2, ud](v2, v1, v3, v12)
  (v16) = vadd.vv[e1m2, ud, fm](v2, v0, v14)
  return (v16)

def _Z6AddSubIu16__rvv_uint64m4_tET_S0_S0_(v0: vec<e1m4>, v1: vec<e1m4>) -> vec<e1m4>:
  (v2) = vsetvlmax[mmul=4, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vrsub.vx[e1m4, ud, fm](v2, v1, v5)
  (v7) = vid.v[e1m4, ud, fm](v2)
  (v10) = scalar[xmul=1, imm=0x0000000000000001]()
  (v9) = vand.vx[e1m4, ud, fm](v2, v7, v10)
  (v12) = vmseq.vx[e1m4, ud, fm](v2, v9, v5)
  (v14) = vmerge.vvm[e1m4, ud](v2, v1, v3, v12)
  (v16) = vadd.vv[e1m4, ud, fm](v2, v0, v14)
  return (v16)

def _Z6AddSubIu16__rvv_uint64m8_tET_S0_S0_(v0: vec<e1m8>, v1: vec<e1m8>) -> vec<e1m8>:
  (v2) = vsetvlmax[mmul=8, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vrsub.vx[e1m8, ud, fm](v2, v1, v5)
  (v7) = vid.v[e1m8, ud, fm](v2)
  (v10) = scalar[xmul=1, imm=0x0000000000000001]()
  (v9) = vand.vx[e1m8, ud, fm](v2, v7, v10)
  (v12) = vmseq.vx[e1m8, ud, fm](v2, v9, v5)
  (v14) = vmerge.vvm[e1m8, ud](v2, v1, v3, v12)
  (v16) = vadd.vv[e1m8, ud, fm](v2, v0, v14)
  return (v16)

def _Z6AddSubIu15__rvv_int8mf8_tET_S0_S0_(v0: vec<ef8mf8>, v1: vec<ef8mf8>) -> vec<ef8mf8>:
  (v2) = vsetvlmax[mmul=1, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8mf8, ud, fm](v2, v1, v5)
  (v7) = vlenb()
  (v8) = scalar[xmul=1, imm=0x0000000000000004]()
  (v9) = srl.xx[width=1](v7, v8)
  (v10) = scalar[xmul=1, imm=0x0000000000000200]()
  (v11) = minu.xx[width=1](v9, v10)
  (v14) = vsetvl[mmul=1, tama](v11)
  (v15) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v12) = scalar_to_vec[ef4mf4, ud](v14, v15)
  (v16) = vec_to_vec[src=ef4mf4, dest=ef8mf4](v12)
  (v17) = vget[part=ef8mf8, src=ef8mf4, idx=0](v16)
  (v19) = vsetvlrelay[mmul=1, src_mmul=1, tama](v2)
  (v18) = vmsne.vx[ef8mf8, ud, fm](v19, v17, v5)
  (v20) = vmerge.vvm[ef8mf8, ud](v19, v1, v3, v18)
  (v22) = vadd.vv[ef8mf8, ud, fm](v19, v0, v20)
  return (v22)

def _Z6AddSubIu15__rvv_int8mf4_tET_S0_S0_(v0: vec<ef8mf4>, v1: vec<ef8mf4>) -> vec<ef8mf4>:
  (v2) = vsetvlmax[mmul=2, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8mf4, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=1, tama]()
  (v11) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef4mf4, ud](v7, v11)
  (v12) = vec_to_vec[src=ef4mf4, dest=ef8mf4](v8)
  (v14) = vsetvlrelay[mmul=2, src_mmul=2, tama](v2)
  (v13) = vmsne.vx[ef8mf4, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef8mf4, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef8mf4, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu15__rvv_int8mf2_tET_S0_S0_(v0: vec<ef8mf2>, v1: vec<ef8mf2>) -> vec<ef8mf2>:
  (v2) = vsetvlmax[mmul=4, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8mf2, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=2, tama]()
  (v11) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef4mf2, ud](v7, v11)
  (v12) = vec_to_vec[src=ef4mf2, dest=ef8mf2](v8)
  (v14) = vsetvlrelay[mmul=4, src_mmul=4, tama](v2)
  (v13) = vmsne.vx[ef8mf2, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef8mf2, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef8mf2, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu14__rvv_int8m1_tET_S0_S0_(v0: vec<ef8m1>, v1: vec<ef8m1>) -> vec<ef8m1>:
  (v2) = vsetvlmax[mmul=8, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8m1, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=4, tama]()
  (v11) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef4m1, ud](v7, v11)
  (v12) = vec_to_vec[src=ef4m1, dest=ef8m1](v8)
  (v14) = vsetvlrelay[mmul=8, src_mmul=8, tama](v2)
  (v13) = vmsne.vx[ef8m1, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef8m1, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef8m1, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu14__rvv_int8m2_tET_S0_S0_(v0: vec<ef8m2>, v1: vec<ef8m2>) -> vec<ef8m2>:
  (v2) = vsetvlmax[mmul=16, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8m2, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=8, tama]()
  (v11) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef4m2, ud](v7, v11)
  (v12) = vec_to_vec[src=ef4m2, dest=ef8m2](v8)
  (v14) = vsetvlrelay[mmul=16, src_mmul=16, tama](v2)
  (v13) = vmsne.vx[ef8m2, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef8m2, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef8m2, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu14__rvv_int8m4_tET_S0_S0_(v0: vec<ef8m4>, v1: vec<ef8m4>) -> vec<ef8m4>:
  (v2) = vsetvlmax[mmul=32, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8m4, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=16, tama]()
  (v11) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef4m4, ud](v7, v11)
  (v12) = vec_to_vec[src=ef4m4, dest=ef8m4](v8)
  (v14) = vsetvlrelay[mmul=32, src_mmul=32, tama](v2)
  (v13) = vmsne.vx[ef8m4, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef8m4, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef8m4, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu14__rvv_int8m8_tET_S0_S0_(v0: vec<ef8m8>, v1: vec<ef8m8>) -> vec<ef8m8>:
  (v2) = vsetvlmax[mmul=64, tama]()
  (v5) = scalar[xmul=f8, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef8m8, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=32, tama]()
  (v11) = scalar[xmul=f4, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef4m8, ud](v7, v11)
  (v12) = vec_to_vec[src=ef4m8, dest=ef8m8](v8)
  (v14) = vsetvlrelay[mmul=64, src_mmul=64, tama](v2)
  (v13) = vmsne.vx[ef8m8, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef8m8, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef8m8, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu16__rvv_int16mf4_tET_S0_S0_(v0: vec<ef4mf4>, v1: vec<ef4mf4>) -> vec<ef4mf4>:
  (v2) = vsetvlmax[mmul=1, tama]()
  (v5) = scalar[xmul=f4, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef4mf4, ud, fm](v2, v1, v5)
  (v7) = vlenb()
  (v8) = scalar[xmul=1, imm=0x0000000000000004]()
  (v9) = srl.xx[width=1](v7, v8)
  (v10) = scalar[xmul=1, imm=0x0000000000000200]()
  (v11) = minu.xx[width=1](v9, v10)
  (v14) = vsetvl[mmul=1, tama](v11)
  (v15) = scalar[xmul=f2, imm=0x0000000000000001]()
  (v12) = scalar_to_vec[ef2mf2, ud](v14, v15)
  (v16) = vec_to_vec[src=ef2mf2, dest=ef8mf2](v12)
  (v17) = vget[part=ef8mf4, src=ef8mf2, idx=0](v16)
  (v18) = vec_to_vec[src=ef8mf4, dest=ef4mf4](v17)
  (v20) = vsetvlrelay[mmul=1, src_mmul=1, tama](v2)
  (v19) = vmsne.vx[ef4mf4, ud, fm](v20, v18, v5)
  (v21) = vmerge.vvm[ef4mf4, ud](v20, v1, v3, v19)
  (v23) = vadd.vv[ef4mf4, ud, fm](v20, v0, v21)
  return (v23)

def _Z6AddSubIu16__rvv_int16mf2_tET_S0_S0_(v0: vec<ef4mf2>, v1: vec<ef4mf2>) -> vec<ef4mf2>:
  (v2) = vsetvlmax[mmul=2, tama]()
  (v5) = scalar[xmul=f4, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef4mf2, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=1, tama]()
  (v11) = scalar[xmul=f2, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef2mf2, ud](v7, v11)
  (v12) = vec_to_vec[src=ef2mf2, dest=ef4mf2](v8)
  (v14) = vsetvlrelay[mmul=2, src_mmul=2, tama](v2)
  (v13) = vmsne.vx[ef4mf2, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef4mf2, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef4mf2, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu15__rvv_int16m1_tET_S0_S0_(v0: vec<ef4m1>, v1: vec<ef4m1>) -> vec<ef4m1>:
  (v2) = vsetvlmax[mmul=4, tama]()
  (v5) = scalar[xmul=f4, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef4m1, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=2, tama]()
  (v11) = scalar[xmul=f2, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef2m1, ud](v7, v11)
  (v12) = vec_to_vec[src=ef2m1, dest=ef4m1](v8)
  (v14) = vsetvlrelay[mmul=4, src_mmul=4, tama](v2)
  (v13) = vmsne.vx[ef4m1, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef4m1, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef4m1, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu15__rvv_int16m2_tET_S0_S0_(v0: vec<ef4m2>, v1: vec<ef4m2>) -> vec<ef4m2>:
  (v2) = vsetvlmax[mmul=8, tama]()
  (v5) = scalar[xmul=f4, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef4m2, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=4, tama]()
  (v11) = scalar[xmul=f2, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef2m2, ud](v7, v11)
  (v12) = vec_to_vec[src=ef2m2, dest=ef4m2](v8)
  (v14) = vsetvlrelay[mmul=8, src_mmul=8, tama](v2)
  (v13) = vmsne.vx[ef4m2, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef4m2, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef4m2, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu15__rvv_int16m4_tET_S0_S0_(v0: vec<ef4m4>, v1: vec<ef4m4>) -> vec<ef4m4>:
  (v2) = vsetvlmax[mmul=16, tama]()
  (v5) = scalar[xmul=f4, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef4m4, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=8, tama]()
  (v11) = scalar[xmul=f2, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef2m4, ud](v7, v11)
  (v12) = vec_to_vec[src=ef2m4, dest=ef4m4](v8)
  (v14) = vsetvlrelay[mmul=16, src_mmul=16, tama](v2)
  (v13) = vmsne.vx[ef4m4, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef4m4, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef4m4, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu15__rvv_int16m8_tET_S0_S0_(v0: vec<ef4m8>, v1: vec<ef4m8>) -> vec<ef4m8>:
  (v2) = vsetvlmax[mmul=32, tama]()
  (v5) = scalar[xmul=f4, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef4m8, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=16, tama]()
  (v11) = scalar[xmul=f2, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[ef2m8, ud](v7, v11)
  (v12) = vec_to_vec[src=ef2m8, dest=ef4m8](v8)
  (v14) = vsetvlrelay[mmul=32, src_mmul=32, tama](v2)
  (v13) = vmsne.vx[ef4m8, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef4m8, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef4m8, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu16__rvv_int32mf2_tET_S0_S0_(v0: vec<ef2mf2>, v1: vec<ef2mf2>) -> vec<ef2mf2>:
  (v2) = vsetvlmax[mmul=1, tama]()
  (v5) = scalar[xmul=f2, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef2mf2, ud, fm](v2, v1, v5)
  (v7) = vlenb()
  (v8) = scalar[xmul=1, imm=0x0000000000000004]()
  (v9) = srl.xx[width=1](v7, v8)
  (v10) = scalar[xmul=1, imm=0x0000000000000200]()
  (v11) = minu.xx[width=1](v9, v10)
  (v14) = vsetvl[mmul=1, tama](v11)
  (v15) = scalar[xmul=1, imm=0x0000000000000001]()
  (v12) = scalar_to_vec[e1m1, ud](v14, v15)
  (v16) = vec_to_vec[src=e1m1, dest=ef8m1](v12)
  (v17) = vget[part=ef8mf2, src=ef8m1, idx=0](v16)
  (v18) = vec_to_vec[src=ef8mf2, dest=ef2mf2](v17)
  (v20) = vsetvlrelay[mmul=1, src_mmul=1, tama](v2)
  (v19) = vmsne.vx[ef2mf2, ud, fm](v20, v18, v5)
  (v21) = vmerge.vvm[ef2mf2, ud](v20, v1, v3, v19)
  (v23) = vadd.vv[ef2mf2, ud, fm](v20, v0, v21)
  return (v23)

def _Z6AddSubIu15__rvv_int32m1_tET_S0_S0_(v0: vec<ef2m1>, v1: vec<ef2m1>) -> vec<ef2m1>:
  (v2) = vsetvlmax[mmul=2, tama]()
  (v5) = scalar[xmul=f2, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef2m1, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=1, tama]()
  (v11) = scalar[xmul=1, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[e1m1, ud](v7, v11)
  (v12) = vec_to_vec[src=e1m1, dest=ef2m1](v8)
  (v14) = vsetvlrelay[mmul=2, src_mmul=2, tama](v2)
  (v13) = vmsne.vx[ef2m1, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef2m1, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef2m1, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu15__rvv_int32m2_tET_S0_S0_(v0: vec<ef2m2>, v1: vec<ef2m2>) -> vec<ef2m2>:
  (v2) = vsetvlmax[mmul=4, tama]()
  (v5) = scalar[xmul=f2, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef2m2, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=2, tama]()
  (v11) = scalar[xmul=1, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[e1m2, ud](v7, v11)
  (v12) = vec_to_vec[src=e1m2, dest=ef2m2](v8)
  (v14) = vsetvlrelay[mmul=4, src_mmul=4, tama](v2)
  (v13) = vmsne.vx[ef2m2, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef2m2, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef2m2, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu15__rvv_int32m4_tET_S0_S0_(v0: vec<ef2m4>, v1: vec<ef2m4>) -> vec<ef2m4>:
  (v2) = vsetvlmax[mmul=8, tama]()
  (v5) = scalar[xmul=f2, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef2m4, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=4, tama]()
  (v11) = scalar[xmul=1, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[e1m4, ud](v7, v11)
  (v12) = vec_to_vec[src=e1m4, dest=ef2m4](v8)
  (v14) = vsetvlrelay[mmul=8, src_mmul=8, tama](v2)
  (v13) = vmsne.vx[ef2m4, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef2m4, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef2m4, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu15__rvv_int32m8_tET_S0_S0_(v0: vec<ef2m8>, v1: vec<ef2m8>) -> vec<ef2m8>:
  (v2) = vsetvlmax[mmul=16, tama]()
  (v5) = scalar[xmul=f2, imm=0x0000000000000000]()
  (v3) = vrsub.vx[ef2m8, ud, fm](v2, v1, v5)
  (v7) = vsetvlmax[mmul=8, tama]()
  (v11) = scalar[xmul=1, imm=0x0000000000000001]()
  (v8) = scalar_to_vec[e1m8, ud](v7, v11)
  (v12) = vec_to_vec[src=e1m8, dest=ef2m8](v8)
  (v14) = vsetvlrelay[mmul=16, src_mmul=16, tama](v2)
  (v13) = vmsne.vx[ef2m8, ud, fm](v14, v12, v5)
  (v15) = vmerge.vvm[ef2m8, ud](v14, v1, v3, v13)
  (v17) = vadd.vv[ef2m8, ud, fm](v14, v0, v15)
  return (v17)

def _Z6AddSubIu15__rvv_int64m1_tET_S0_S0_(v0: vec<e1m1>, v1: vec<e1m1>) -> vec<e1m1>:
  (v2) = vsetvlmax[mmul=1, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vrsub.vx[e1m1, ud, fm](v2, v1, v5)
  (v7) = vid.v[e1m1, ud, fm](v2)
  (v10) = scalar[xmul=1, imm=0x0000000000000001]()
  (v9) = vand.vx[e1m1, ud, fm](v2, v7, v10)
  (v12) = vmseq.vx[e1m1, ud, fm](v2, v9, v5)
  (v14) = vmerge.vvm[e1m1, ud](v2, v1, v3, v12)
  (v16) = vadd.vv[e1m1, ud, fm](v2, v0, v14)
  return (v16)

def _Z6AddSubIu15__rvv_int64m2_tET_S0_S0_(v0: vec<e1m2>, v1: vec<e1m2>) -> vec<e1m2>:
  (v2) = vsetvlmax[mmul=2, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vrsub.vx[e1m2, ud, fm](v2, v1, v5)
  (v7) = vid.v[e1m2, ud, fm](v2)
  (v10) = scalar[xmul=1, imm=0x0000000000000001]()
  (v9) = vand.vx[e1m2, ud, fm](v2, v7, v10)
  (v12) = vmseq.vx[e1m2, ud, fm](v2, v9, v5)
  (v14) = vmerge.vvm[e1m2, ud](v2, v1, v3, v12)
  (v16) = vadd.vv[e1m2, ud, fm](v2, v0, v14)
  return (v16)

def _Z6AddSubIu15__rvv_int64m4_tET_S0_S0_(v0: vec<e1m4>, v1: vec<e1m4>) -> vec<e1m4>:
  (v2) = vsetvlmax[mmul=4, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vrsub.vx[e1m4, ud, fm](v2, v1, v5)
  (v7) = vid.v[e1m4, ud, fm](v2)
  (v10) = scalar[xmul=1, imm=0x0000000000000001]()
  (v9) = vand.vx[e1m4, ud, fm](v2, v7, v10)
  (v12) = vmseq.vx[e1m4, ud, fm](v2, v9, v5)
  (v14) = vmerge.vvm[e1m4, ud](v2, v1, v3, v12)
  (v16) = vadd.vv[e1m4, ud, fm](v2, v0, v14)
  return (v16)

def _Z6AddSubIu15__rvv_int64m8_tET_S0_S0_(v0: vec<e1m8>, v1: vec<e1m8>) -> vec<e1m8>:
  (v2) = vsetvlmax[mmul=8, tama]()
  (v5) = scalar[xmul=1, imm=0x0000000000000000]()
  (v3) = vrsub.vx[e1m8, ud, fm](v2, v1, v5)
  (v7) = vid.v[e1m8, ud, fm](v2)
  (v10) = scalar[xmul=1, imm=0x0000000000000001]()
  (v9) = vand.vx[e1m8, ud, fm](v2, v7, v10)
  (v12) = vmseq.vx[e1m8, ud, fm](v2, v9, v5)
  (v14) = vmerge.vvm[e1m8, ud](v2, v1, v3, v12)
  (v16) = vadd.vv[e1m8, ud, fm](v2, v0, v14)
  return (v16)

